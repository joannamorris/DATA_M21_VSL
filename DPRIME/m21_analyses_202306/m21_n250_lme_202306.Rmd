---
title: "M21 202303 n250 lme"
author: "Joanna Morris"
date: "`r Sys.Date()`"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  message=FALSE, comment = "")
```

This R script contains the code for analysing the morph 21 erp data for the 200-300 ms time window.

1. First we load the libraries we need

```{r}
library(readr)
library(psych)
library(dplyr)
library(tidyr)
library(ggplot2)
```

Let's load the N250 erp data file and the spelling and  vocab data, then  we join the files. We will use the `inner_join` rather than the `full_join` function in order to eliminate rows with missing data.

```{r}
sv_202303.na <- read_csv("m21_spell_vocab_raw_z_pca.csv", show_col_types = FALSE)
n250 <- read_csv("S101-177_n250.csv", show_col_types = FALSE)
n250 <- inner_join(sv_202303.na,n250, by = "SubjID")  #join subject PCA data
```

Let's save a `.csv` file with the data from the combined dataset 

```{r}
write_csv(n250, "202303_sv_n250_rmna.csv")
```


We will create a subset with only the electrode sites we will be 
analysing—F3, Fz, F4, C3, Cz, C4, P3, Pz, P4


```{r c12}
sites = c(3,2, 25, 7, 20, 21, 12, 11, 16)
n250_9 <- dplyr::filter(n250, chindex %in% sites)

```


7. We then create separate columns, one for each independent variable (anteriority, laterality, morphological family size). To do this we have to use the`mutate` function from the dplyr package along with the `case_when` function. The `case_when` function  is a sequence of two-sided formulas. The left hand side determines which values match this case. The right hand side provides the replacement value.

```{r}
n250_9 <- dplyr::mutate(n250_9,
                        anteriority = case_when(grepl("F", chlabel) ~ "Frontal",
                                                grepl("C", chlabel) ~ "Central",
                                                grepl("P", chlabel) ~ "Parietal"))

n250_9 <- dplyr::mutate(n250_9,
                        laterality = case_when(grepl("3", chlabel) ~ "Left",
                                               grepl("z", chlabel) ~ "Midline",
                                               grepl("Z", chlabel) ~ "Midline",
                                               grepl("4", chlabel) ~ "Right"))



n250_9 <- dplyr::mutate(n250_9,
                        fam_size = case_when(grepl("small", binlabel) ~ "Small",
                                             grepl("large", binlabel) ~ "Large"))
```


8. We then create a smaller dataset with only the columns we need

```{r}
n250_9b <- dplyr::select(n250_9, 
                             SubjID, 
                             lang_type, 
                             anteriority, 
                             laterality, 
                             fam_size,
                             value,
                             chlabel,
                             binlabel)
```

9. We then divide dataset into 3 separate ones—for "words", "simple nonwords" and "complex nonwords"

```{r}
n250_words <- dplyr::filter(n250_9b, grepl("Critical_word",binlabel))
n250_nwsmpl <- dplyr::filter(n250_9b, grepl("simple",binlabel))
n250_nwcplx <- dplyr::filter(n250_9b, grepl("complex",binlabel))
```



#Plot Means

Get condition means

```{r get_means}

#Define standard error of the mean function

sem <- function(x) sd(x)/sqrt(length(x))

(cw.cond.means <- n250_words |> 
   group_by(fam_size, lang_type) |> 
   summarise(mean = mean(value), 
             se = sem(value),
             num_stim = n()))


(nw_smp.cond.means <- n250_nwsmpl |> 
    group_by(fam_size, lang_type) |> 
    summarise(mean = mean(value), 
              se = sem(value),
              num_stim = n()))

(nw_cpx.cond.means <- n250_nwcplx |> 
    group_by(fam_size, lang_type) |> 
    summarise(mean = mean(value), 
              se = sem(value),
              num_stim = n()))
```

Barplots

```{r c15, fig.height= 6, fig.width= 6, echo=FALSE}
library(gridExtra)
p1 <-  cw.cond.means |> ggplot(aes(x=lang_type, 
                                   y=mean, 
                                   fill = fam_size, 
                                   ymin = mean - se, 
                                   ymax = mean + se)) +
  coord_cartesian(xlim = NULL, 
                  ylim = c(-2, 2.2), 
                  expand = TRUE, 
                  default = FALSE,
                  clip = "on") +
  geom_col(position = "dodge", width = 0.5, color = "black")  +
  ylab("Voltage (microvolts)")  +  
  xlab("")  + 
  ggtitle("Complex Words") +
  scale_fill_manual(values = c("coral2", "deepskyblue3"))+ 
  geom_errorbar(width = .08, position = position_dodge(0.5)) + 
  theme_classic() + 
   geom_text(aes(label = round(mean, digits = 2)),
             colour = "black", 
             size = 2.5, 
             vjust = -4, 
             position = position_dodge(.5))+
  guides(fill=guide_legend(title="Morphological Family Size"))

p2 <-  nw_smp.cond.means |> ggplot(aes(x=lang_type, 
                                       y=mean, fill = fam_size, 
                                       ymin = mean - se, 
                                       ymax = mean + se)) +
  coord_cartesian(xlim = NULL, 
                  ylim = c(-2, 2.2), 
                  expand = TRUE, 
                  default = FALSE,
                  clip = "on") +
  geom_col(position = "dodge", width = .7, color = "black")  +
  xlab("")  + 
  ylab("Voltage (microvolts)")  +  
  ggtitle("Simple NonWords") +
  scale_fill_manual(values = c("coral2", "deepskyblue3"))+ 
  geom_errorbar(width = .08, position = position_dodge(0.7)) + 
  theme_classic() + 
   geom_text(aes(label = round(mean, digits = 2)),
             colour = "black", 
             size = 2.5, 
             vjust = -2.5, 
             position = position_dodge(.5)) +
  guides(fill=guide_legend(title="Morphological Family Size"))

p3 <-  nw_cpx.cond.means |> ggplot(aes(x=lang_type, 
                                       y=mean, 
                                       fill = fam_size, 
                                       ymin = mean - se, 
                                       ymax = mean + se)) +
  coord_cartesian(xlim = NULL, 
                  ylim = c(-2, 2.2), 
                  expand = TRUE, 
                  default = FALSE,
                  clip = "on") +
  geom_col(position = "dodge", width = .7, color = "black")  +
  xlab("Participant Reading Style")  + 
  ylab("Voltage (microvolts)")  +  
  ggtitle("Complex NonWords") +
  scale_fill_manual(values = c("coral2", "deepskyblue3"))+ 
  geom_errorbar(width = .08, position = position_dodge(0.7)) + 
  theme_classic() + 
   geom_text(aes(label = round(mean, digits = 2)),
             colour = "black", 
             size = 2.5, 
             vjust = -2.1,  
             position = position_dodge(.5)) +
  guides(fill=guide_legend(title="Morphological Family Size"))

grid.arrange(p1, p2, p3)
```

# LME
```{r}
library(lme4)
```


# COMPLEX WORDS
```{r }
cw_null.model = lmer(value ~ 1 + (1|SubjID) , 
                     data= n250_words, REML=FALSE)
summary(cw_null.model)

# Main effects models with random intercepts
cw_main.model = lmer(value ~ lang_type + fam_size + (1 + fam_size|SubjID) ,
                     data= n250_words, REML=FALSE)
summary(cw_main.model)

# Interaction effects models with random intercepts
cw_inter.model = lmer(value ~ lang_type * fam_size + (1 + fam_size|SubjID) ,
                      data= n250_words, REML=FALSE)
summary(cw_inter.model)

anova(cw_null.model,cw_main.model)
anova(cw_main.model,cw_inter.model)

```


## SIMPLE NONWORDS
```{r}
nw.smpl_null.model = lmer(value ~ 1 + (1|SubjID) , 
                          data= n250_nwsmpl, REML=FALSE)
summary(nw.smpl_null.model)

# Main effects models with random intercepts
nw.smpl_main.model = lmer(value ~ lang_type + fam_size + (1 + fam_size|SubjID) ,
                          data= n250_nwsmpl, REML=FALSE)
summary(nw.smpl_main.model)

# Interaction effects models with random intercepts
nw.smpl_inter.model = lmer(value ~ lang_type * fam_size + (1 + fam_size|SubjID) ,
                           data= n250_nwsmpl, REML=FALSE)
summary(nw.smpl_inter.model)

anova(nw.smpl_null.model,nw.smpl_main.model)
anova(nw.smpl_main.model,nw.smpl_inter.model)
```

# COMPLEX NONWORDS

```{r}

nw.cplx_null.model = lmer(value ~ 1 + (1|SubjID) ,
                          data= n250_nwcplx, REML=FALSE)
summary(nw.cplx_null.model)

# Main effects models with random intercepts
nw.cplx_main.model = lmer(value ~ lang_type + fam_size + (1 + fam_size|SubjID) , 
                          data= n250_nwcplx, REML=FALSE)
summary(nw.cplx_main.model)

# Interaction effects models with random intercepts
nw.cplx_inter.model = lmer(value ~ lang_type * fam_size  + (1 + fam_size|SubjID),
                           data= n250_nwcplx, REML=FALSE)
summary(nw.cplx_inter.model)

anova(nw.cplx_null.model,nw.cplx_main.model)
anova(nw.cplx_main.model,nw.cplx_inter.model)

```

### Model Comparisons

```{r c17}
anova(cw_null.model,cw_main.model)
anova(cw_main.model,cw_inter.model)

anova(nw.smpl_null.model,nw.smpl_main.model)
anova(nw.smpl_main.model,nw.smpl_inter.model)

anova(nw.cplx_null.model,nw.cplx_main.model)
anova(nw.cplx_main.model,nw.cplx_inter.model)
```


```{r}
# COMPLEX WORDS

cw_null.model = lmer(value ~ 1 + (1|SubjID) , 
                     data= n250_words, REML=FALSE)
summary(cw_null.model)

# Main effects models with random intercepts
cw_main.model = lmer(value ~ lang_type + (1 |SubjID) ,
                     data= n250_words, REML=FALSE)
summary(cw_main.model)
anova(cw_null.model,cw_main.model)
```

```{r}
# COMPLEX WORDS

cw_null.model = lmer(value ~ 1 + (1|SubjID) , 
                     data= n250_words, REML=FALSE)
summary(cw_null.model)

# Main effects models with random intercepts
cw_main.model = lmer(value ~ fam_size + (1 |SubjID) ,
                     data= n250_words, REML=FALSE)
summary(cw_main.model)
anova(cw_null.model,cw_main.model)
```